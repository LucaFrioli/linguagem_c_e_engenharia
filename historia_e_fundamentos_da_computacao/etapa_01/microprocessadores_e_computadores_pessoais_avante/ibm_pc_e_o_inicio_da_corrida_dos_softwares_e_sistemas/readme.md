# **A Evolução Tecnológica entre o Apple II e o IBM PC: O Início da Revolução do Software e dos Sistemas Operacionais**

#### **Introdução: O Salto da Computação Pessoal**

Com o lançamento do **Apple II em 1977**, o mercado de computadores pessoais deixou de ser um nicho restrito a entusiastas e passou a atrair o interesse de **empresas e consumidores finais**. O Apple II introduziu conceitos inovadores como **gráficos coloridos, um design integrado e um ecossistema de software crescente**, tornando os PCs ferramentas viáveis para trabalho e entretenimento.

No entanto, a revolução não parou por aí. O sucesso do Apple II incentivou grandes corporações a **entrarem na corrida**, e foi assim que, em 1981, a **IBM lançou o IBM PC (5150)**. Esse evento marcou **uma nova fase da computação pessoal**, na qual o foco não estava apenas na melhoria do hardware, mas também na criação de **softwares mais sofisticados e sistemas operacionais mais avançados**.

A partir desse momento, a corrida tecnológica não se limitava mais a processadores mais rápidos ou memórias maiores, mas sim a quem poderia oferecer **o sistema operacional mais eficiente, as aplicações mais úteis e a interface mais amigável**.

---

## **1. Evoluções Tecnológicas e Científicas no Hardware (Apple II → IBM PC)**

A transição entre o Apple II e o IBM PC trouxe uma série de avanços técnicos e científicos, que foram impulsionados não apenas por novas descobertas na computação, mas também pelos avanços nas áreas de **física, química e matemática aplicadas à eletrônica e à arquitetura computacional**.

### **1.1. Arquitetura de Hardware: Do 6502 ao 8088**

O Apple II utilizava o **MOS 6502**, um microprocessador eficiente e barato, mas com limitações em desempenho e capacidade de endereçamento de memória. Já o **IBM PC adotou o Intel 8088**, uma versão modificada do **Intel 8086**, que possuía uma **arquitetura de 16 bits internamente**, mas mantinha um barramento externo de 8 bits, tornando-o compatível com hardware mais barato.

O 8088 trouxe avanços significativos, como:

- **Maior capacidade de endereçamento de memória** (até 1 MB, contra os 64 KB do 6502).
- **Suporte a operações matemáticas mais complexas**, essencial para aplicações de engenharia e negócios.
- **Instruções mais avançadas**, permitindo maior flexibilidade para programadores.

Essa evolução foi crucial para que o IBM PC pudesse rodar **softwares mais poderosos**, incluindo planilhas, processadores de texto e, eventualmente, interfaces gráficas.

### **1.2. Avanços na Física e Química dos Componentes**

A evolução dos computadores entre o **Apple II e o IBM PC** foi fortemente impulsionada pelos avanços na ciência dos **materiais semicondutores**, permitindo a miniaturização dos transistores de silício e a melhoria das memórias RAM. Esses avanços não apenas **aumentaram a eficiência dos microprocessadores**, mas também reduziram o consumo energético e tornaram os sistemas computacionais mais acessíveis.

#### **Miniaturização dos Transistores de Silício e o Impacto Físico-Químico**

O coração dos microprocessadores da época era o **silício dopado**, um semicondutor que passou por aprimoramentos na fabricação para permitir **a redução do tamanho dos transistores** sem perder eficiência elétrica.

A estrutura dos transistores evoluiu de tecnologias mais simples, como o **MOSFET de canal n e p (Metal-Oxide-Semiconductor Field-Effect Transistor)**, para estruturas mais refinadas como os transistores CMOS (**Complementary MOS**), que combinavam ambos os tipos para um menor consumo de energia e maior eficiência.

##### **Dopagem do Silício e o Controle da Condutividade**

O **silício puro (Si)** possui uma banda de valência completa, o que significa que ele não conduz eletricidade de forma eficiente. Para torná-lo um semicondutor útil, ele passa por um **processo de dopagem**, no qual pequenas quantidades de elementos químicos são adicionadas para modificar suas propriedades elétricas.

As principais dopagens utilizadas foram:

- **Tipo N (Negativo):** Adição de elementos do grupo 15 da tabela periódica, como **fósforo (P) ou arsênio (As)**, que possuem 5 elétrons de valência. Isso cria um excesso de elétrons livres, facilitando a condução elétrica.
- **Tipo P (Positivo):** Adição de elementos do grupo 13, como **boro (B) ou alumínio (Al)**, que possuem apenas 3 elétrons de valência, criando lacunas (holes) que funcionam como portadores de carga positiva.

A equação da condutividade em semicondutores dopados segue a relação:

\[
\sigma = q (n \mu_n + p \mu_p)
\]

Onde:

- \( \sigma \) é a condutividade elétrica,
- \( q \) é a carga elementar do elétron (\(1.602 \times 10^{-19} C\)),
- \( n \) e \( p \) são as concentrações de elétrons e lacunas, respectivamente,
- \( \mu_n \) e \( \mu_p \) são as mobilidades dos elétrons e das lacunas.

A miniaturização dos transistores seguiu a **Lei de Moore**, que previa a duplicação da quantidade de transistores em um chip a cada **18-24 meses**, o que levou a um **aumento exponencial do poder de processamento**.

##### **Redução da Largura do Canal e Impacto na Eficiência Energética**

A diminuição da largura do canal do MOSFET (tamanho do transistor) impactou diretamente os seguintes fatores:

1. **Aumento da densidade de transistores no chip**, resultando em maior poder computacional.
2. **Redução da tensão de operação**, minimizando o aquecimento e o consumo de energia.
3. **Diminuição do tempo de comutação**, permitindo frequências de clock mais altas.

A tensão de operação do transistor (\( V\_{GS} \)) segue a equação aproximada da corrente de dreno do MOSFET na região linear:

\[
I*D = \mu_n C*{ox} \frac{W}{L} \left( V*{GS} - V*{th} \right) V\_{DS}
\]

Onde:

- \( I_D \) é a corrente de dreno,
- \( \mu_n \) é a mobilidade do elétron,
- \( C\_{ox} \) é a capacitância da camada de óxido,
- \( W \) e \( L \) são a largura e o comprimento do canal,
- \( V\_{GS} \) é a tensão porta-fonte,
- \( V\_{th} \) é a tensão de limiar,
- \( V\_{DS} \) é a tensão dreno-fonte.

Com a redução de \( L \), a corrente \( I_D \) aumenta, resultando em maior velocidade de comutação.

---

#### **A Evolução das Memórias RAM: Das MOS RAM às DRAM**

A transição da tecnologia **MOS RAM (Static RAM - SRAM)** para **Dynamic RAM (DRAM)** trouxe benefícios significativos em termos de **capacidade, custo e consumo de energia**.

##### **SRAM vs. DRAM: Diferenças Estruturais e Físico-Químicas**

| Característica         | SRAM (Static RAM)          | DRAM (Dynamic RAM)                     |
| ---------------------- | -------------------------- | -------------------------------------- |
| **Armazenamento**      | Usa 6 transistores por bit | Usa 1 transistor + 1 capacitor por bit |
| **Velocidade**         | Mais rápida                | Mais lenta                             |
| **Consumo de energia** | Maior                      | Menor                                  |
| **Densidade**          | Baixa (ocupa mais espaço)  | Alta (mais compacta)                   |
| **Custo**              | Alto                       | Baixo                                  |

A DRAM armazena dados em **capacitores**, enquanto a SRAM usa **flip-flops de transistores**. Os capacitores da DRAM precisam ser **recarregados constantemente** devido ao fenômeno da **descarga dielétrica**.

##### **Equação de Descarga do Capacitor na DRAM**

A descarga do capacitor na DRAM pode ser modelada pela equação da descarga exponencial:

\[
V(t) = V_0 e^{-t/RC}
\]

Onde:

- \( V(t) \) é a tensão no capacitor em um tempo \( t \),
- \( V_0 \) é a tensão inicial,
- \( R \) é a resistência de fuga,
- \( C \) é a capacitância.

Se a tensão \( V(t) \) cair abaixo de um limite, o bit armazenado será perdido, razão pela qual a DRAM precisa de um circuito de **refresh** para recarregar os capacitores periodicamente.

##### **Vantagens e Impacto no IBM PC**

A transição para a DRAM permitiu que **memórias de maior capacidade fossem fabricadas a custos menores**, tornando possível expandir a RAM do **IBM PC para até 640 KB**, um grande salto em relação ao Apple II, que possuía **apenas 48 KB de RAM**.

Esse aumento na capacidade de memória viabilizou **softwares mais complexos**, incluindo **sistemas operacionais multitarefa**, que se tornariam comuns nas gerações seguintes.

---

### **A Base Científica da Revolução Computacional**

A evolução dos semicondutores e das memórias entre o Apple II e o IBM PC foi um marco na história da computação. Os avanços físico-químicos permitiram:

- **A miniaturização dos transistores**, aumentando a densidade e a eficiência energética dos microprocessadores.
- **O aprimoramento das técnicas de dopagem do silício**, permitindo maior controle da condutividade elétrica.
- **A substituição das SRAMs por DRAMs**, possibilitando o armazenamento de grandes volumes de dados a um custo menor.

---

## **2. O Avanço do Software: De Simples Programas a Sistemas Operacionais**

Se os computadores estavam se tornando mais poderosos, fazia sentido que os softwares também precisassem evoluir para **acompanhar esse crescimento**. Mas essa evolução não aconteceu de forma linear; ela foi impulsionada por uma série de avanços tecnológicos que transformaram não apenas como os computadores eram utilizados, mas também **como os softwares eram projetados, desenvolvidos e distribuídos**.

### **2.1. O Primeiro Software que Mudou o Jogo**

O divisor de águas para a adoção em massa dos computadores pessoais foi o **VisiCalc**, lançado em **1979** para o Apple II. Ele foi o **primeiro software de planilha eletrônica**, permitindo que **empresas e contadores automatizassem cálculos financeiros**, algo revolucionário para a época.

Antes do VisiCalc, os computadores pessoais eram vistos mais como brinquedos para entusiastas ou ferramentas para programadores. Mas esse software **provou que um computador podia ser uma ferramenta essencial para o mercado de trabalho**, ajudando na **gestão de dados, cálculos e modelagem financeira**.

O sucesso do VisiCalc mostrou que o verdadeiro valor dos computadores pessoais não estava apenas no hardware, mas no **que eles podiam fazer**. Isso levou a um boom de softwares voltados para **produtividade e negócios**, culminando na criação de **novos sistemas operacionais para gerenciar melhor esses programas**.

### **2.2. O IBM PC e o MS-DOS: O Software Domina o Hardware**

Com o lançamento do **IBM PC em 1981**, o cenário da computação mudou drasticamente. A IBM, que dominava o mercado de computadores corporativos, decidiu entrar no segmento de computadores pessoais, mas precisava de um sistema operacional. Como a empresa não tinha tempo para desenvolver um próprio, **terceirizou o trabalho para a Microsoft**.

A Microsoft, então uma empresa pequena focada em linguagens de programação, viu uma **oportunidade gigantesca** e adquiriu os direitos do **QDOS (Quick and Dirty Operating System)**, que foi modificado e lançado como **MS-DOS**.

O impacto do MS-DOS foi gigantesco. Diferente dos sistemas anteriores, ele foi criado para ser **aberto a hardware de terceiros**, o que permitiu que **outras empresas fabricassem clones do IBM PC, desde que rodassem o MS-DOS**. Isso criou um **mercado massivo para softwares baseados em MS-DOS**, consolidando a Microsoft como a **líder em sistemas operacionais para PCs**.

A partir desse momento, os computadores pessoais deixaram de ser um nicho e se tornaram **ferramentas essenciais para empresas e consumidores**, impulsionando **uma nova era de desenvolvimento de software**.

### **2.3. O Início da Corrida pelos Sistemas Operacionais**

Com o sucesso do MS-DOS, outras empresas começaram a investir em sistemas operacionais mais avançados. Paralelamente, o **sistema UNIX**, que já existia desde os anos 1970 em ambientes acadêmicos e corporativos, começou a ser **adaptado para máquinas menores**. Esse movimento abriu caminho para o surgimento de variantes do UNIX voltadas para computadores pessoais, incluindo:

- **Xenix** (da Microsoft)
- **BSD UNIX** (derivado da Universidade da Califórnia, Berkeley)
- **MINIX** (um UNIX educacional que inspirou o desenvolvimento do Linux)

Esses sistemas operacionais foram fundamentais para estabelecer **novos paradigmas de multitarefa, memória virtual e sistemas de arquivos mais eficientes**, o que ampliou as capacidades dos computadores pessoais.

### **2.4. O Avanço das Linguagens de Programação**

Com a disseminação dos computadores pessoais e sistemas operacionais mais complexos, houve um **aumento na demanda por linguagens de programação mais sofisticadas**. Até então, linguagens como **BASIC e Assembly** dominavam o mercado, mas logo surgiram linguagens **mais estruturadas e eficientes**, incluindo:

- **C** (amplamente adotada para sistemas UNIX e desenvolvimento de software de alto desempenho);
- **Pascal** (popular no ensino e em ambientes de desenvolvimento estruturado);
- **Ada** (desenvolvida para aplicações críticas, como software militar e aeroespacial);
- **Fortran e COBOL** (que continuaram a evoluir para atender às necessidades científicas e empresariais).

As influências dessas linguagens vieram principalmente de **três pilares fundamentais**:

1. **Binário e Assembly**: Linguagens de baixo nível ainda eram essenciais para a otimização de software, especialmente em sistemas operacionais e drivers de hardware.
2. **BASIC**: Introduziu a ideia de uma linguagem acessível para iniciantes, o que inspirou novas linguagens voltadas para produtividade.
3. **C e UNIX**: A estrutura modular e portável da linguagem C permitiu que fosse amplamente adotada para o desenvolvimento de sistemas operacionais e aplicações de alto desempenho.

### **2.5. O Impacto na Evolução do Software**

Com essas mudanças, os softwares passaram a ser desenvolvidos **com um foco muito maior na experiência do usuário**, levando a avanços como:

- **Ambientes gráficos mais intuitivos**;
- **Multitarefa e gerenciamento eficiente de memória**;
- **Expansão do mercado de software, com aplicativos para diversos setores**;
- **Criação de novas linguagens de programação para ambientes gráficos, como Visual Basic e Object Pascal**.

O avanço do software entre o Apple II e o IBM PC **não foi apenas uma evolução natural**, mas uma verdadeira **revolução tecnológica e conceitual**. Esse período estabeleceu **os fundamentos para o software moderno**, consolidando conceitos como:

- **A importância da interface gráfica**;
- **A necessidade de linguagens mais eficientes**;
- **A padronização dos sistemas operacionais**;
- **O crescimento da indústria de software como um mercado independente do hardware**.

Com essas bases estabelecidas, a computação pessoal se tornou uma **força dominante na economia e na sociedade**, abrindo caminho para a era digital que vivemos hoje.

---

### **3. A Corrida pela Interface Gráfica e a Revolução da Computação Pessoal**

#### **3.1. A Ascensão das Interfaces Gráficas: Do Xerox PARC ao Macintosh**

Enquanto os sistemas operacionais baseados em linha de comando, como o MS-DOS, dominavam o mercado, uma revolução silenciosa estava em andamento nos laboratórios do **Xerox PARC (Palo Alto Research Center)**. Pesquisadores do PARC desenvolveram o **Xerox Alto (1973)**, um dos primeiros computadores pessoais a apresentar uma **interface gráfica (GUI - Graphical User Interface)** baseada em janelas, ícones e menus, além do uso do **mouse** como principal meio de interação.

Steve Jobs visitou o Xerox PARC no final dos anos 1970 e rapidamente percebeu o potencial dessa abordagem revolucionária. Inspirada pelo trabalho da Xerox, a Apple lançou o **Lisa (1983)**, o primeiro computador comercial com interface gráfica. No entanto, devido ao seu alto custo e desempenho limitado, o Lisa não teve o impacto esperado. Foi com o **Macintosh (1984)** que a Apple conseguiu popularizar as interfaces gráficas, oferecendo um sistema operacional baseado em janelas e ícones, acessível a um público mais amplo. Esse modelo de interação intuitiva mudaria para sempre a forma como os usuários comuns interagiam com computadores.

O sucesso do Macintosh forçou a **Microsoft a desenvolver o Windows**, inicialmente como uma camada gráfica sobre o MS-DOS. Em 1985, foi lançado o **Windows 1.0**, que, apesar de suas limitações, marcou o início da grande disputa entre **Mac e PC**, consolidando o papel das interfaces gráficas como o futuro da computação pessoal.

---

#### **3.2. O Impacto da GUI e a Expansão para Novos Dispositivos**

A introdução da GUI não apenas mudou a forma como os computadores eram usados, mas também incentivou o desenvolvimento de **novas categorias de dispositivos computacionais**, como **portáteis, microcontroladores e videogames**.

##### **Computadores Portáteis e a Democratização da Computação**

A interface gráfica tornou os computadores mais acessíveis e intuitivos, aumentando a demanda por dispositivos menores e mais práticos. Isso impulsionou o desenvolvimento dos **primeiros notebooks**, como o **Compaq Portable (1983)** e o **Macintosh Portable (1989)**. Com o avanço dos semicondutores e das memórias RAM mais compactas e eficientes, os computadores portáteis começaram a se tornar viáveis para uso empresarial e doméstico, preparando o terreno para a explosão dos laptops e, mais tarde, dos dispositivos móveis.

##### **Microcontroladores e Computação Embarcada**

Paralelamente, os avanços na computação gráfica e na miniaturização dos processadores permitiram o desenvolvimento dos **microcontroladores**, pequenos chips programáveis que passaram a ser utilizados em **automação industrial, eletrodomésticos e sistemas embarcados**. Empresas como a Intel e a Texas Instruments começaram a investir pesadamente nesse setor, lançando microcontroladores baseados na **arquitetura RISC**, que oferecia maior eficiência energética e poder computacional adequado para sistemas dedicados.

##### **Videogames e o Surgimento das GPUs**

O crescimento das interfaces gráficas também impactou diretamente o mercado de **videogames**, que passou de gráficos rudimentares baseados em **sprites 2D** para experiências visuais mais complexas. Empresas como a Nintendo, Sega e Sony começaram a investir em **processadores gráficos dedicados (GPUs)**, que aceleravam o processamento de imagens e tornaram possível a criação de jogos tridimensionais. Esse avanço levou ao desenvolvimento de **linguagens especializadas para programação gráfica**, como o **OpenGL (1992)** e, posteriormente, o **DirectX (1995)**, que permitiram a criação de gráficos mais realistas e imersivos.

---

#### **3.3. O Papel das Novas Linguagens de Programação e Protocolos de Rede**

Com o crescimento exponencial da capacidade computacional e a necessidade de **desenvolvimento de softwares mais robustos e complexos**, novas linguagens de programação surgiram para lidar com os desafios da nova era digital.

##### **O Nascimento do C++ e a Evolução da Programação Orientada a Objetos**

O **C++**, desenvolvido por **Bjarne Stroustrup** no início dos anos 1980, surgiu como uma extensão do **C**, adicionando suporte à **programação orientada a objetos (OOP)**. Essa abordagem permitiu um desenvolvimento mais modular e escalável, sendo rapidamente adotada para o desenvolvimento de **sistemas operacionais, jogos e aplicações gráficas**.

##### **Linguagens para GPUs e Computação Paralela**

Com o avanço das GPUs, surgiram linguagens e frameworks específicos para programação gráfica e computação paralela, como o **CUDA (2007)** da NVIDIA e o **OpenCL (2009)**. Essas tecnologias permitiram o processamento massivo de dados em paralelo, revolucionando não apenas os gráficos de videogames, mas também áreas como inteligência artificial e simulações científicas.

##### **A Criação da Ethernet e a Expansão da Internet**

Durante esse mesmo período, a necessidade de conectar computadores entre si levou ao desenvolvimento de **novos protocolos de comunicação**. O **Ethernet**, criado por **Robert Metcalfe** em 1973, tornou-se o padrão para redes locais (LAN), permitindo a interconexão de computadores dentro de empresas e universidades. Esse avanço foi fundamental para a **expansão da Internet**, que nos anos 1990 se tornaria um fenômeno global, transformando a computação e impulsionando ainda mais a necessidade de novos sistemas operacionais e linguagens de programação adaptadas ao ambiente distribuído da web.

---

### **O Impacto da Revolução Gráfica na Computação Moderna**

A introdução das interfaces gráficas não apenas tornou os computadores mais acessíveis ao público, mas também **abriu caminho para novos paradigmas computacionais**, incluindo dispositivos portáteis, microcontroladores, videogames avançados e redes globais interconectadas. A necessidade de software mais sofisticado levou ao surgimento de **novas linguagens de programação** e arquiteturas especializadas, criando um ecossistema tecnológico que continua a evoluir até os dias de hoje.

O período entre o lançamento do **Macintosh e o crescimento da computação gráfica e em rede** marcou o início de uma nova era digital, onde hardware, software e conectividade passaram a se desenvolver de forma integrada, moldando o mundo moderno da tecnologia.

---

## **Conclusão: O Legado da Revolução Computacional**

A evolução da computação entre o **Apple II e o IBM PC** e além, não foi apenas uma questão de avanços tecnológicos isolados. Ela foi impulsionada pelo acúmulo de séculos de descobertas científicas em áreas fundamentais como **matemática, física, química, engenharia eletrônica e teoria da computação**. Cada inovação no hardware e no software foi possível graças a um **entendimento profundo dos princípios científicos que regem os circuitos, os algoritmos e os modelos computacionais**.

Hoje, ao olharmos para a computação moderna, é essencial **reconhecer que a evolução da tecnologia não ocorre em um vácuo**. O desenvolvimento de novos processadores, a criação de algoritmos mais eficientes e até a revolução da inteligência artificial são possíveis apenas porque cientistas, matemáticos e engenheiros exploram **as fronteiras do conhecimento**.

A matemática, por exemplo, tem sido a base fundamental para a computação moderna. **Alan Turing**, considerado o pai da computação, desenvolveu o conceito de **Máquina de Turing**, que é o modelo teórico de todos os computadores modernos, e também foi responsável pela formulação dos princípios da **inteligência artificial**. Já **Claude Shannon**, com sua teoria da informação, estabeleceu as bases para a codificação e transmissão de dados, algo essencial para a comunicação digital e segurança da informação.

Na física, **Richard Feynman** não apenas revolucionou a mecânica quântica, mas também lançou as bases da **computação quântica**, que poderá substituir os processadores tradicionais no futuro. **John Bardeen**, junto com Walter Brattain e William Shockley, desenvolveu o **transistor**, que viabilizou a criação de microcomputadores e, mais tarde, a revolução da computação pessoal.

A química também desempenhou um papel essencial, com cientistas como **Linus Pauling**, que estabeleceu os princípios da ligação química e ajudou no desenvolvimento de materiais semicondutores usados na fabricação de chips. Da mesma forma, **Marie Curie**, com seus estudos sobre radioatividade, forneceu fundamentos que mais tarde contribuíram para tecnologias como detectores de radiação e fontes de energia para sistemas eletrônicos.

Na engenharia de computação, **John von Neumann** revolucionou a arquitetura dos computadores ao propor a **arquitetura von Neumann**, utilizada até hoje na construção de computadores modernos. Já **Donald Knuth**, um dos maiores cientistas da computação, sistematizou o estudo dos algoritmos, estabelecendo a **análise de complexidade computacional**, fundamental para otimização de software.

Assim, compreender a fundo não apenas as linguagens de programação, mas também **os princípios que regem os semicondutores, as arquiteturas de computação, os modelos algorítmicos e até mesmo as equações da física e da química aplicadas ao hardware**, é o que diferencia um programador comum de um verdadeiro engenheiro de software e hardware.

Se o Apple II e o IBM PC marcaram uma revolução, o futuro da computação promete mudanças ainda mais disruptivas — da computação quântica à nanotecnologia, da inteligência artificial aos sistemas bioeletrônicos. E para moldar esse futuro, é necessário ir além da superfície e **mergulhar nos fundamentos científicos e matemáticos que sustentam o mundo digital**.

Portanto, a verdadeira revolução não está apenas no próximo grande avanço tecnológico, mas no conhecimento que o torna possível. O convite está lançado: aprofunde-se, questione, estude e torne-se um dos arquitetos da próxima era da computação.

Se hà um comprometimento para além do óbvio, e você chegou até aqui, minimamente quer dizer que não está acomodado com sua situação como desenvolvedor ou desenvolvedora, então na próxima etapa antes mesmo de nos aprofundarmos em linguagens de programação, iremos pincelar, as teorias que fazem parte da verdadeira evolução tecnológica, tornando-nos mais que simples programadores, mas sim ciêntistas e engenheiros de softwares, dispostos a estar na vanguarda das inovações. Mesmo que isso queira dizer retornar um pouco nos fundamentos essenciais, do pensamento ciêntífico, e despertar o lado explorador que está dentro de nós. Para começar vamos entender as teoria de Von Neumann, que influenciam até hoje como a computação moderna evolui, então [clique aqui, e vamos continuar esta jornada!](../../teorias_mais_importantes_para_a_computação_hoje/readme.md)
